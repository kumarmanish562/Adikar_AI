# RAG Legal Assistant - Training & Testing Guide

## ğŸ¯ Overview
This RAG (Retrieval-Augmented Generation) Legal Assistant processes Indian legal documents and enables semantic search and question-answering.

**Note**: This is **NOT** a traditional ML training process. We use **pre-trained embeddings** (no model training required).

## ğŸ“‹ Prerequisites

1. **Activate the virtual environment**:
   ```powershell
   cd "m:\PROJECT 2026\Adikar_AI"
   .\rag_env\Scripts\Activate.ps1
   ```

2. **Install dependencies**:
   ```powershell
   cd ml_engine
   pip install -r requirements.txt
   ```

## ğŸš€ Training Process (3 Steps)

### Step 1: PDF Processing & Chunking
**Purpose**: Extract text from PDFs and create chunks for embedding

```powershell
python train_step1_process_pdfs.py
```

**What it does**:
- âœ… Reads all PDFs from `data/raw_pdfs/english` and `data/raw_pdfs/hindi`
- âœ… Extracts text using PyPDF2
- âœ… Cleans and chunks text (500 chars per chunk, 100 char overlap)
- âœ… Saves chunks to `data/processed/chunks.json`

**Output**: `data/processed/chunks.json`

---

### Step 2: Embedding Generation & FAISS Index
**Purpose**: Convert text chunks to vectors and create search index

```powershell
python train_step2_embeddings.py
```

**What it does**:
- âœ… Loads chunks from Step 1
- âœ… Generates embeddings using sentence-transformers (384-dimensional)
- âœ… Creates FAISS index for fast similarity search
- âœ… Tests basic search functionality
- âœ… Saves embeddings and index to disk

**Output**: 
- `data/processed/embeddings.pkl`
- `data/processed/faiss_index.bin`

â±ï¸ **Time**: 5-15 minutes (depends on number of PDFs)

---

### Step 3: Testing & Evaluation
**Purpose**: Test the RAG system and evaluate performance

```powershell
python test_rag_system.py
```

**What it does**:
- âœ… Loads the trained vector database
- âœ… Generates test questions (10 legal queries)
- âœ… Tests retrieval accuracy
- âœ… Calculates match scores
- âœ… Demonstrates example queries

**Output**: `data/processed/evaluation_results.json`

---

## ğŸ“Š Expected Results

After running all 3 steps, you should have:
- âœ… Processed chunks from ~15 legal PDFs
- âœ… 5000+ text chunks indexed
- âœ… FAISS search index ready
- âœ… ~70-90% average match score on test questions

## ğŸ” Testing the System

After completing all steps, you can query the RAG system:

```python
from embedding_engine import RAGVectorDatabase
from config import EMBEDDINGS_FILE, FAISS_INDEX_FILE

# Load the database
db = RAGVectorDatabase()
db.load(EMBEDDINGS_FILE, FAISS_INDEX_FILE)

# Search for relevant chunks
results = db.search("Can police arrest without warrant?", k=5)

for result in results:
    print(f"Score: {result['score']:.3f}")
    print(f"Source: {result['chunk']['source']}")
    print(f"Text: {result['chunk']['text'][:200]}...\n")
```

## ğŸ“ Directory Structure

```
ml_engine/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/
â”‚   â”‚   â”œâ”€â”€ english/     # English legal PDFs (8 files)
â”‚   â”‚   â””â”€â”€ hindi/       # Hindi legal PDFs (7 files)
â”‚   â””â”€â”€ processed/       # Generated outputs
â”‚       â”œâ”€â”€ chunks.json
â”‚       â”œâ”€â”€ embeddings.pkl
â”‚       â”œâ”€â”€ faiss_index.bin
â”‚       â”œâ”€â”€ test_questions.json
â”‚       â””â”€â”€ evaluation_results.json
â”œâ”€â”€ config.py            # Configuration
â”œâ”€â”€ pdf_processor.py     # PDF processing module
â”œâ”€â”€ embedding_engine.py  # Embedding & FAISS module
â”œâ”€â”€ test_generator.py    # Test dataset generator
â”œâ”€â”€ train_step1_process_pdfs.py    # Step 1 script
â”œâ”€â”€ train_step2_embeddings.py      # Step 2 script
â”œâ”€â”€ test_rag_system.py             # Step 3 script
â””â”€â”€ requirements.txt
```

## âš ï¸ Troubleshooting

### Error: "No module named 'config'"
- Make sure you're in the `ml_engine` directory
- The script automatically adds the directory to Python path

### Error: "Chunks file not found"
- Run Step 1 first: `python train_step1_process_pdfs.py`

### Error: "No PDF files found"
- Check if PDFs exist in `data/raw_pdfs/english` and `data/raw_pdfs/hindi`

### Error: "FAISS index not found"
- Run Step 2 first: `python train_step2_embeddings.py`

## ğŸ”— Next Steps

1. **Integrate with LLM**: Use Claude, Gemini, or Antigravity API to generate answers
2. **Deploy as API**: Create a Flask/FastAPI service
3. **Add Hindi support**: Implement Hindi query translation
4. **Fine-tune parameters**: Adjust chunk size, overlap, and TOP_K

## ğŸ“ Notes

- **No traditional training**: This RAG system uses pre-trained sentence-transformers
- **GPU not required**: CPU processing works fine (just slower)
- **Incremental updates**: You can re-run Step 1 if you add more PDFs
- **Fast inference**: FAISS enables sub-second searches on thousands of ch
